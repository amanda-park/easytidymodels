% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/marsRegress.R
\name{marsRegress}
\alias{marsRegress}
\title{Multi Adaptive Regressive Spline}
\usage{
marsRegress(
  response = response,
  recipe = rec,
  folds = folds,
  train = train_df,
  test = test_df,
  gridNumber = 10,
  evalMetric = "rmse"
)
}
\arguments{
\item{response}{Character. The variable that is the response for analysis.}

\item{recipe}{A recipes::recipe object.}

\item{folds}{A rsample::vfolds_cv object.}

\item{train}{Data frame/tibble. The training data set.}

\item{test}{Data frame/tibble. The testing data set.}

\item{gridNumber}{Numeric. The size of the grid to tune on. Default is 15.}

\item{evalMetric}{Character. The regression metric you want to evaluate the model's accuracy on. Default is RMSE. Can choose from the following:
\itemize{
\item rmse
\item mae
\item rsq
\item mase
\item ccc
\item icc
\item huber_loss
}}
}
\value{
A list with the following elements:
\itemize{
\item Training set predictions
\item Training set evaluation on RMSE and MAE
\item Testing set predictions
\item Testing set evaluation on RMSE and MAE
\item Tuned model object
}
}
\description{
Fits a MARS regression model.
}
\details{
Note - Tunes the following parameters:
\itemize{
\item num_terms: The number of features that will be retained in the final model.
\item prod_degree: The highest possible degree of interaction between features. A value of 1 indicates an additive model while a value of 2 allows, but does not guarantee, two-way interactions between features.
\item prune_method: The type of pruning. Possible values are listed in ?earth.
}
}
\examples{
library(easytidymodels)
library(dplyr)
library(recipes)
utils::data(penguins, package = "modeldata")

#Define your response variable and formula object here
resp <- "bill_length_mm"
formula <- stats::as.formula(paste(resp, ".", sep="~"))

#Split data into training and testing sets
split <- trainTestSplit(penguins, responseVar = resp)

#Create recipe for feature engineering for dataset, varies based on data working with
rec <- recipe(formula, split$train) \%>\% prep()
train_df <- bake(rec, split$train)
test_df <- bake(rec, split$test)
folds <- cvFolds(train_df)

#Fit a MARS regression object (commented out only due to long run time)
#marsReg <- marsRegress(recipe = rec, response = resp,
#folds = folds, train = train_df, test = test_df, evalMetric = "rmse")

#Visualize training data and its predictions
#marsReg$trainPred \%>\% select(.pred, !!resp)

#View how model metrics for RMSE, R-Squared, and MAE look for training data
#marsReg$trainScore

#Visualize testing data and its predictions
#marsReg$testPred \%>\% select(.pred, !!resp)

#View how model metrics for RMSE, R-Squared, and MAE look for testing data
#marsReg$testScore

#See the final model chosen for MARS based on optimizing for your chosen evaluation metric
#marsReg$final

#See how model fit looks based on another evaluation metric
#marsReg$tune \%>\% tune::show_best("mae")
}
