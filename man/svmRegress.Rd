% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/svmRegress.R
\name{svmRegress}
\alias{svmRegress}
\title{Support Vector Machine Regression}
\usage{
svmRegress(
  response = response,
  recipe = rec,
  folds = folds,
  train = train_df,
  test = test_df,
  gridNumber = 15,
  evalMetric = "rmse"
)
}
\arguments{
\item{response}{Character. The variable that is the response for analysis.}

\item{recipe}{A recipes::recipe object.}

\item{folds}{A rsample::vfolds_cv object.}

\item{train}{Data frame/tibble. The training data set.}

\item{test}{Data frame/tibble. The testing data set.}

\item{gridNumber}{Numeric. The size of the grid to tune on. Default is 15.}

\item{evalMetric}{Character. The regression metric you want to evaluate the model's accuracy on. Default is RMSE. Can choose from the following:
\itemize{
\item rmse
\item mae
\item rsq
\item mase
\item ccc
\item icc
\item huber_loss
}}
}
\value{
A list with the following elements:
\itemize{
\item Training set predictions
\item Training set evaluation on RMSE and MAE
\item Testing set predictions
\item Testing set evaluation on RMSE and MAE
\item Tuned model object
}
}
\description{
Fits a radial basis Support Vector Machine Regression.
}
\details{
Note - tunes the following parameters:
\itemize{
\item cost: The cost of predicting a sample within or on the wrong side of the margin.
\item rbf_sigma: The precision parameter for the radial basis function.
\item margin: The epsilon in the SVM insensitive loss function (regression only).
}
}
\examples{
library(easytidymodels)
library(dplyr)
library(recipes)
utils::data(penguins, package = "modeldata")

#Define your response variable and formula object here
resp <- "bill_length_mm"
formula <- stats::as.formula(paste(resp, ".", sep="~"))

#Split data into training and testing sets
split <- trainTestSplit(penguins, responseVar = resp)

#Create recipe for feature engineering for dataset, varies based on data working with
rec <- recipe(formula, split$train) \%>\% prep()
train_df <- bake(rec, split$train)
test_df <- bake(rec, split$test)
folds <- cvFolds(train_df)

#Fit an SVM regression object (commented out only due to long run time)
#svmReg <- svmRegress(recipe = rec, response = resp,
#folds = folds, train = train_df, test = test_df, evalMetric = "rmse")

#Visualize training data and its predictions
#svmReg$trainPred \%>\% select(.pred, !!resp)

#View how model metrics for RMSE, R-Squared, and MAE look for training data
#svmReg$trainScore

#Visualize testing data and its predictions
#svmReg$testPred \%>\% select(.pred, !!resp)

#View how model metrics for RMSE, R-Squared, and MAE look for testing data
#svmReg$testScore

#See the final model chosen by SVM based on optimizing for your chosen evaluation metric
#svmReg$final

#See how model fit looks based on another evaluation metric
#svmReg$tune \%>\% tune::show_best("mae")
}
