% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xgBinaryClassif.R
\name{xgBinaryClassif}
\alias{xgBinaryClassif}
\title{XGBoost Binary Classification}
\usage{
xgBinaryClassif(
  gridNumber = 10,
  recipe = rec,
  folds = cvFolds,
  train = datTrain,
  test = datTest,
  response = response,
  treeNum = 100,
  calcFeatImp = TRUE,
  evalMetric = "bal_accuracy"
)
}
\arguments{
\item{gridNumber}{Numeric. Size of the grid you want XGBoost to explore. Default is 10.}

\item{recipe}{A recipe object.}

\item{folds}{A rsample::vfolds_cv object.}

\item{train}{Data frame/tibble. The training data set.}

\item{test}{Data frame/tibble. The testing data set.}

\item{response}{Character. The variable that is the response for analysis.}

\item{treeNum}{Numeric. The number of trees to evaluate your model with. Default is 100.}

\item{calcFeatImp}{Logical. Do you want to calculate feature importance for your model? If not, set = FALSE.}

\item{evalMetric}{Character. The classification metric you want to evaluate the model's accuracy on. Default is bal_accuracy. List of metrics available to choose from:
\itemize{
\item bal_accuracy
\item mn_log_loss
\item roc_auc
\item mcc
\item kap
\item sens
\item spec
\item precision
\item recall
}}
}
\value{
A list with the following outputs:
\itemize{
\item Training confusion matrix
\item Training model metric score
\item Testing confusion matrix
\item Testing model metric score
\item Final model chosen by XGBoost
\item Tuned model
\item Feature importance plot
\item Feature importance variable
}
}
\description{
Runs XGBoost for binary classification.
}
\details{
What the model tunes:
\itemize{
\item mtry: The number of predictors that will be randomly sampled at each split when creating the tree models.
\item min_n: The minimum number of data points in a node that are required for the node to be split further.
\item tree_depth: The maximum depth of the tree (i.e. number of splits).
\item learn_rate: The rate at which the boosting algorithm adapts from iteration-to-iteration.
\item loss_reduction: The reduction in the loss function required to split further.
\item sample_size: The amount of data exposed to the fitting routine.
}

What you set specifically:
\itemize{
\item trees: Default is 100. Sets the number of trees contained in the ensemble. A larger values increases runtime but (ideally) leads to more robust outcomes.
}
}
\examples{
library(easytidymodels)
library(dplyr)
library(recipes)
utils::data(penguins, package = "modeldata")
#Define your response variable and formula object here
resp <- "sex"
formula <- stats::as.formula(paste(resp, ".", sep="~"))
#Split data into training and testing sets
split <- trainTestSplit(penguins, stratifyOnResponse = TRUE,
responseVar = resp)
#Create recipe for feature engineering for dataset, varies based on data working with
rec <- recipe(formula, data = split$train) \%>\% step_knnimpute(!!resp) \%>\%
step_dummy(all_nominal(), -all_outcomes()) \%>\%
step_medianimpute(all_predictors()) \%>\% step_normalize(all_predictors()) \%>\%
step_dummy(all_nominal(), -all_outcomes()) \%>\% step_nzv(all_predictors()) \%>\%
step_corr(all_numeric(), -all_outcomes(), threshold = .8) \%>\% prep()
train_df <- bake(rec, split$train)
test_df <- bake(rec, split$test)
folds <- cvFolds(train_df)

#xgClass <- xgBinaryClassif(recipe = rec, response = resp, folds = folds,
#train = train_df, test = test_df, evalMetric = "roc_auc")

#Visualize training data and its predictions
#xgClass$trainConfMat

#View how model metrics look
#xgClass$trainScore

#Visualize testing data and its predictions
#xgClass$testConfMat

#View how model metrics look
#xgClass$testScore

#See the final model chosen by XGBoost based on optimizing for your chosen evaluation metric
#xgClass$final

#See how model fit looks based on another evaluation metric
#xgClass$tune \%>\% tune::show_best("bal_accuracy")

#Feature importance plot
#xgClass$featImpPlot

#Feature importance variables
#xgClass$featImpVars

}
